{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import flask\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from flask import Flask, redirect,url_for, request, render_template\n",
    "from flask_ngrok import run_with_ngrok\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import time\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(r'\\archive\\books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_tags = pd.read_csv(r'\\archive\\book_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(r'\\archive\\ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(r'\\archive\\tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(books['authors'])\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "titles = books['title']\n",
    "image_url=books['image_url']\n",
    "indices = pd.Series(books.index, index=books['title'])\n",
    "\n",
    "def authors_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    data=pd.DataFrame(books['title'].iloc[book_indices])\n",
    "    data['date']=books['authors']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_join_DF = pd.merge(book_tags, tags, left_on='tag_id', right_on='tag_id', how='inner')\n",
    "books_with_tags = pd.merge(books, tags_join_DF, left_on='book_id', right_on='goodreads_book_id', how='inner')\n",
    "tf1 = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix1 = tf1.fit_transform(books_with_tags['tag_name'].head(10000))\n",
    "cosine_sim1 = linear_kernel(tfidf_matrix1, tfidf_matrix1)\n",
    "titles1 = books['title']\n",
    "indices1 = pd.Series(books.index, index=books['title'])\n",
    "\n",
    "def tags_recommendations(title):\n",
    "    idx = indices1[title]\n",
    "    sim_scores = list(enumerate(cosine_sim1[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    data2=pd.DataFrame(books['title'].iloc[book_indices])\n",
    "    data2['date']=books['authors']\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputsumm(input_text):\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(input_text)\n",
    "    f = dict()\n",
    "    for i in words:\n",
    "        i = i.lower()\n",
    "        if i in stopWords:\n",
    "            continue\n",
    "        if i in f:\n",
    "            f[i] += 1\n",
    "        else:\n",
    "            f[i] = 1\n",
    "    sentences = sent_tokenize(input_text)\n",
    "    fsent = dict()\n",
    "    for j in sentences:\n",
    "        for x, y in f.items():\n",
    "            if x in j.lower():\n",
    "                if j in fsent:\n",
    "                    fsent[j] += y\n",
    "                else:\n",
    "                    fsent[j] = y\n",
    "    count = 0\n",
    "    for k in fsent:\n",
    "        count += fsent[k]\n",
    "    average = int(count / len(fsent))\n",
    "    output_text = ''\n",
    "    for p in sentences:\n",
    "        if (p in fsent) and (fsent[p] > (1.2 * average)):\n",
    "            output_text += \" \"+p\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drowsinessdetector():\n",
    "    K.clear_session()\n",
    "    mixer.init()\n",
    "    sound = mixer.Sound(r'\\Drowsiness detection\\Drowsiness detection\\alarm.wav')\n",
    "\n",
    "    face = cv2.CascadeClassifier(r'\\Drowsiness detection\\Drowsiness detection\\haar cascade files\\haarcascade_frontalface_alt.xml')\n",
    "    leye = cv2.CascadeClassifier(r'\\Drowsiness detection\\Drowsiness detection\\haar cascade files\\haarcascade_lefteye_2splits.xml')\n",
    "    reye = cv2.CascadeClassifier(r'\\Drowsiness detection\\Drowsiness detection\\haar cascade files\\haarcascade_righteye_2splits.xml')\n",
    "    lbl=['Close','Open']\n",
    "\n",
    "    model = load_model(r'\\Drowsiness detection\\Drowsiness detection\\models\\cnncat2.h5')\n",
    "    path = os.getcwd()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    count=0\n",
    "    score=0\n",
    "    thicc=2\n",
    "    rpred=[99]\n",
    "    lpred=[99]\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        height,width = frame.shape[:2] \n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "        left_eye = leye.detectMultiScale(gray)\n",
    "        right_eye =  reye.detectMultiScale(gray)\n",
    "\n",
    "        cv2.rectangle(frame, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 1 )\n",
    "\n",
    "        for (x,y,w,h) in right_eye:\n",
    "            r_eye=frame[y:y+h,x:x+w]\n",
    "            count=count+1\n",
    "            r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "            r_eye = cv2.resize(r_eye,(24,24))\n",
    "            r_eye= r_eye/255\n",
    "            r_eye=  r_eye.reshape(24,24,-1)\n",
    "            r_eye = np.expand_dims(r_eye,axis=0)\n",
    "            rpred = model.predict_classes(r_eye)\n",
    "            if(rpred[0]==1):\n",
    "                lbl='Open' \n",
    "            if(rpred[0]==0):\n",
    "                lbl='Closed'\n",
    "                break\n",
    "\n",
    "        for (x,y,w,h) in left_eye:\n",
    "            l_eye=frame[y:y+h,x:x+w]\n",
    "            count=count+1\n",
    "            l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)  \n",
    "            l_eye = cv2.resize(l_eye,(24,24))\n",
    "            l_eye= l_eye/255\n",
    "            l_eye=l_eye.reshape(24,24,-1)\n",
    "            l_eye = np.expand_dims(l_eye,axis=0)\n",
    "            lpred = model.predict_classes(l_eye)\n",
    "            if(lpred[0]==1):\n",
    "                lbl='Open'   \n",
    "            if(lpred[0]==0):\n",
    "                lbl='Closed'\n",
    "                break\n",
    "\n",
    "        if(rpred[0]==0 and lpred[0]==0):\n",
    "            score=score+1\n",
    "            cv2.putText(frame,\"Closed\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "            # if(rpred[0]==1 or lpred[0]==1):\n",
    "        else:\n",
    "            score=score-1\n",
    "            cv2.putText(frame,\"Open\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "        if(score<0):\n",
    "            score=0   \n",
    "        cv2.putText(frame,'Score:'+str(score),(100,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "        if(score>15):\n",
    "            #person is feeling sleepy so we beep the alarm\n",
    "            cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n",
    "            try:\n",
    "                sound.play()\n",
    "            except:  # isplaying = False\n",
    "                pass\n",
    "            if(thicc<16):\n",
    "                thicc= thicc+2\n",
    "            else:\n",
    "                thicc=thicc-2\n",
    "            if(thicc<2):\n",
    "                    thicc=2\n",
    "            cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thicc) \n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [30/Dec/2020 14:21:24] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [30/Dec/2020 14:21:24] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ishan\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ishan\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\", line 1177, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"C:\\Users\\Ishan\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\flask_ngrok.py\", line 70, in start_ngrok\n",
      "    ngrok_address = _run_ngrok()\n",
      "  File \"C:\\Users\\Ishan\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\flask_ngrok.py\", line 38, in _run_ngrok\n",
      "    tunnel_url = j['tunnels'][0]['public_url']  # Do the parsing of the get\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "app = flask.Flask(__name__, template_folder=r'\\template', static_folder=r'\\static')\n",
    "run_with_ngrok(app)\n",
    "\n",
    "@app.route('/',methods=['GET','POST'])\n",
    "def home():\n",
    "    return render_template('home.html') \n",
    "\n",
    "@app.route('/byauthor',methods=['GET','POST'])\n",
    "def byauthor():\n",
    "    if flask.request.method == 'GET':\n",
    "        return(flask.render_template('byauthor.html'))\n",
    "            \n",
    "    if flask.request.method == 'POST':\n",
    "        m_name = flask.request.form['movie_name']  #movie=book\n",
    "        m_name = m_name.title()\n",
    "        try: \n",
    "            result_final = authors_recommendations(m_name)\n",
    "            names = []\n",
    "            dates = []\n",
    "            for i in range(len(result_final)):\n",
    "                names.append(result_final.iloc[i][0])\n",
    "                dates.append(result_final.iloc[i][1])\n",
    "\n",
    "            return flask.render_template('i3.html',movie_names=names,movie_date=dates,search_name=m_name)\n",
    "        except KeyError:\n",
    "            \n",
    "            return(flask.render_template('i2.html',name=m_name))\n",
    "\n",
    "@app.route('/bytag',methods=['POST','GET'])\n",
    "def bytag():\n",
    "    if flask.request.method=='GET':\n",
    "        return(flask.render_template('bytag.html'))\n",
    "    \n",
    "    if flask.request.method=='POST':\n",
    "        m_name=flask.request.form['movie_name']\n",
    "        m_name=m_name.title()\n",
    "        try:\n",
    "            result_final=tags_recommendations(m_name)\n",
    "            names=[]\n",
    "            dates=[]\n",
    "            for i in range(len(result_final)):\n",
    "                names.append(result_final.iloc[i][0])\n",
    "                dates.append(result_final.iloc[i][1])\n",
    "            return flask.render_template('i3.html',movie_names=names,movie_date=dates,search_name=m_name)\n",
    "        except KeyError:\n",
    "            return(flask.render_template('i2.html',name=m_name))\n",
    "        \n",
    "@app.route('/gettext',methods=['POST','GET'])\n",
    "def gettext():\n",
    "    try:\n",
    "        return render_template('gettext.html')\n",
    "    except ZeroDivisionError:\n",
    "        return render_template('gettext.html')\n",
    "    return render_template('gettext.html') \n",
    "\n",
    "@app.route('/textsummary',methods=['POST','GET'])\n",
    "def textsummary():\n",
    "    try:\n",
    "         if request.method == 'POST':\n",
    "            textvalue = request.form.get(\"textarea\", None)\n",
    "            return render_template('textsummary.html', res=outputsumm(textvalue))\n",
    "    except ZeroDivisionError:\n",
    "        return render_template('gettext.html')\n",
    "    return render_template('textsummary.html')\n",
    "    \n",
    "@app.route('/drowsiness',methods=['POST','GET'])\n",
    "def drowsiness():\n",
    "    try:\n",
    "        drowsinessdetector()\n",
    "    except AttributeError:\n",
    "        return render_template('home.html') \n",
    "    return render_template('home.html') \n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random,shutil\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),class_mode='categorical' ):\n",
    "\n",
    "    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',class_mode=class_mode,target_size=target_size)\n",
    "\n",
    "BS= 32\n",
    "TS=(24,24)\n",
    "train_batch= generator('data/train',shuffle=True, batch_size=BS,target_size=TS)\n",
    "valid_batch= generator('data/valid',shuffle=True, batch_size=BS,target_size=TS)\n",
    "SPE= len(train_batch.classes)//BS\n",
    "VS = len(valid_batch.classes)//BS\n",
    "print(SPE,VS)\n",
    "\n",
    "\n",
    "# img,labels= next(train_batch)\n",
    "# print(img.shape)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Conv2D(32,(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "\n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "    \n",
    "#randomly turn neurons on and off to improve convergence\n",
    "    Dropout(0.25),\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "    Flatten(),\n",
    "#fully connected to get all relevant data\n",
    "    Dense(128, activation='relu'),\n",
    "#one more dropout for convergence' sake :) \n",
    "    Dropout(0.5),\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_batch, validation_data=valid_batch,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)\n",
    "\n",
    "model.save('models/cnnCat2.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__) #originally install 2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras==2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
